{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from DQNAgent import DQNAgent\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-import if you did changes\n",
    "reload(DQNAgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your environment\n",
    "env = gym.make('MinAtar/Breakout-v1', render_mode=\"rgb_array\")\n",
    "\n",
    "# Print observation and action space infos\n",
    "print(f\"Training on {env.spec.id}\")\n",
    "print(f\"Observation space: {env.observation_space}\")\n",
    "print(f\"Action space: {env.action_space}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyperparameters, Hint: Change as you see fit\n",
    "LR = 0.001\n",
    "BATCH_SIZE = 8\n",
    "REPLAY_BUFFER_SIZE = 100_000\n",
    "UPDATE_FREQ = 100\n",
    "EPS_START = 0.5\n",
    "EPS_END = 0.05\n",
    "SCHEDULE_DURATION = 15_000\n",
    "NUM_EPISODES = 1_000\n",
    "DISCOUNT_FACTOR = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train DQN\n",
    "agent = DQNAgent(\n",
    "    env, \n",
    "    gamma=DISCOUNT_FACTOR,\n",
    "    lr=LR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    eps_start=EPS_START,\n",
    "    eps_end=EPS_END,\n",
    "    schedule_duration=SCHEDULE_DURATION,\n",
    "    update_freq=UPDATE_FREQ,\n",
    "    maxlen=REPLAY_BUFFER_SIZE,\n",
    ")\n",
    "stats = agent.train(NUM_EPISODES)\n",
    "\n",
    "\n",
    "smoothing_window=20\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5), tight_layout=True)\n",
    "\n",
    "# Plot the episode length over time\n",
    "ax = axes[0]\n",
    "ax.plot(stats.episode_lengths)\n",
    "ax.set_xlabel(\"Episode\")\n",
    "ax.set_ylabel(\"Episode Length\")\n",
    "ax.set_title(\"Episode Length over Time\") \n",
    "\n",
    "# Plot the episode reward over time\n",
    "ax = axes[1]\n",
    "rewards_smoothed = pd.Series(stats.episode_rewards).rolling(smoothing_window, min_periods=smoothing_window).mean()\n",
    "ax.plot(rewards_smoothed)\n",
    "ax.set_xlabel(\"Episode\")\n",
    "ax.set_ylabel(\"Episode Reward (Smoothed)\")\n",
    "ax.set_title(f\"Episode Reward over Time\\n(Smoothed over window size {smoothing_window})\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
